{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Реализация посимвольной генерации текста на основе LSTM"
      ],
      "metadata": {
        "id": "C5rFouh4XZqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном примере мы используем тексты из произведений Ницше, немецкого философа конца XIX века (в переводе на английский язык). Таким образом, в результате обучения у нас получится языковая модель, обладающая специфическими особенностями, характерными для произведений Ницше, а не обобщенная модель английского языка."
      ],
      "metadata": {
        "id": "z_pHIIqTXiEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка и парсинг исходного текстового файла"
      ],
      "metadata": {
        "id": "IJsw4_gVXnSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKurO6PYac3q",
        "outputId": "14581376-3084-4dd1-abbc-08c453af4518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsYdi2ZEVOw6",
        "outputId": "b10f07a1-a044-42db-c17c-ae13c1f12acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/minimaxir/textgenrnn/blob/master/datasets/reddit_apple_android_2000.txt\n",
            "      0/Unknown \u001b[1m0s\u001b[0m 0s/stepCorpus length: 780271\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "path = keras.utils.get_file('nietzsche.txt', origin='https://github.com/minimaxir/textgenrnn/blob/master/datasets/reddit_apple_android_2000.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем извлечем частично перекрывающиеся последовательности с длиной maxlen, выполним прямое кодирование и упакуем в трехмерный массив Numpy x с формой (последовательности, максимальная_длина, уникальные_символы). Одновременно подготовим массив y с соответствующими целями: векторы с символами, полученные прямым кодированием, которые следуют за каждой извлеченной последовательностью.\n",
        "Векторизация последовательностей символов\n"
      ],
      "metadata": {
        "id": "dbb1ptjpXo7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 60 #Извлечение последовательностей по 60 символов\n",
        "step = 3 #Новые последовательности выбираются через каждые 3 символа\n",
        "sentences = [] #Хранение извлеченных последовательностей\n",
        "next_chars = [] #Хранение целей (символов, следующих за последовательностями)\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text))) #Список уникальных символов в корпусе\n",
        "print('Unique characters:', len(chars))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars) # Словарь, отображающий уникальные символы в их индексы в списке «chars»\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "        y[i, char_indices[next_chars[i]]] = 1 #Прямое кодирование символов в бинарные массивы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UzO64S0XvQA",
        "outputId": "d391a74f-b101-44fe-8e44-bc43ae82228b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences: 260071\n",
            "Unique characters: 108\n",
            "Vectorization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Конструирование сети\n",
        "Эта сеть состоит из единственного слоя LSTM, за которым следует классификатор Dense с функцией softmax выбора из всех возможных символов. Но имейте в виду, что рекуррентные нейронные сети не единственный способ генерирования после-довательностей данных; одномерные сверточные сети тоже показали превосходные результаты в решении этой задачи.\n",
        "Модель с единственным слоем LSTM для предсказания следующего символа\n"
      ],
      "metadata": {
        "id": "kghNvR35YFCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n"
      ],
      "metadata": {
        "id": "omsxOynyXy4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как цели имеют формат прямого кодирования, используем для обучения модели функцию потерь categorical_crossentropy.\n",
        "Конфигурация компилируемой модели\n"
      ],
      "metadata": {
        "id": "r_Nmi8dUYmbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "DVcoJKx7YJ0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели и извлечение образцов из нее\n",
        "Имея обученную модель и фрагмент начального текста, можно сгенерировать новый текст, выполнив следующие пункты:\n",
        "1. Извлечь из модели распределение вероятностей следующего символа для имеющегося на данный момент сгенерированного текста.\n",
        "2. Выполнить взвешивание распределения с заданной температурой.\n",
        "3. Выбрать следующий символ в соответствии с вновь взвешенным распределением вероятностей.\n",
        "4. Добавить новый символ в конец текста.\n",
        "Вот код, который мы используем для взвешивания оригинального распределения вероятностей, возвращаемого моделью, и извлечения индекса символа (функция выборки).\n",
        "Функция выборки следующего символа с учетом прогнозов модели\n"
      ],
      "metadata": {
        "id": "bD3sf5dKYx1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "o8pZH-p7Yddp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец, следующий цикл повторяет обучение и генерирует текст. Для начала сгенерируем текст, использовав разные температуры после каждой эпохи. Это позволит вам увидеть, как меняется генерируемый тест по мере схождения модели и как температура влияет на стратегию выбора.\n",
        "Цикл генерации текста\n"
      ],
      "metadata": {
        "id": "n0-1LCvdZC5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "for epoch in range(1, 61):  # Обучение модели в течение 60 эпох\n",
        "    print('epoch', epoch)\n",
        "    model.fit(x, y, batch_size=128, epochs=1)\n",
        "\n",
        "    # Генерация текста только на 15, 30 и 60 эпохах\n",
        "    if epoch in [15, 30, 60]:\n",
        "        # Выбор случайного начального текста\n",
        "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "        generated_text = text[start_index: start_index + maxlen]\n",
        "        print('\\n--- Epoch {} - Generating with seed: \"{}\"'.format(epoch, generated_text))\n",
        "\n",
        "        for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "            print('\\n------ temperature:', temperature)\n",
        "            sys.stdout.write(generated_text)\n",
        "\n",
        "            # Генерация 400 символов\n",
        "            for i in range(400):\n",
        "                sampled = np.zeros((1, maxlen, len(chars)))\n",
        "                for t, char in enumerate(generated_text):\n",
        "                    sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "                preds = model.predict(sampled, verbose=0)[0]\n",
        "                next_index = sample(preds, temperature)\n",
        "                next_char = chars[next_index]\n",
        "\n",
        "                generated_text += next_char\n",
        "                generated_text = generated_text[1:]\n",
        "                sys.stdout.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "            print('\\n' + '-'*50)  # Разделитель между разными температурами\n",
        "        print('\\n' + '='*70 + '\\n')  # Разделитель между разными эпохами"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWr2QRqpY1WQ",
        "outputId": "99481e4c-b131-4c1a-b372-7d292fe4e295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 1.8846\n",
            "epoch 2\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.0306\n",
            "epoch 3\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9432\n",
            "epoch 4\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9036\n",
            "epoch 5\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.4755\n",
            "epoch 6\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.3106\n",
            "epoch 7\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.2747\n",
            "epoch 8\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.3352\n",
            "epoch 9\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.3960\n",
            "epoch 10\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.1762\n",
            "epoch 11\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.1127\n",
            "epoch 12\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.4214\n",
            "epoch 13\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.1367\n",
            "epoch 14\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.0354\n",
            "epoch 15\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9883\n",
            "\n",
            "--- Epoch 15 - Generating with seed: \"lative\">til people who wear glasses may notice in that the &\"\n",
            "\n",
            "------ temperature: 0.2\n",
            "lative\">til people who wear glasses may notice in that the &#039;the prodick to android a to a pro pro proper and store a the is android a second a secred and and some in the macor is and and in android saction to compen a to a to to compay and to compare and to compan and to can to compen a to compare and to compen and to compen to is a to compen to to compan and in ipads a to saction to compay and secon is and in the macor the and in the macto is the and\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 0.5\n",
            "nd secon is and in the macor the and in the macto is the and android on a the and android a next ary prodick to in comple propery is ipad design samphter to a can compay macto use icon android a flate about it to secre, compan saction airpods are it accos, is on mac to can and stort on in steguse a the noot a imaging the have secing i macire one on for a a to today and on to compen to chime a finger to secop macor on comphing a mus the wele of of is on bel\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 1.0\n",
            "er to secop macor on comphing a mus the wele of of is on belel i gb.\\r\",\"linkime sopff\\r\",\"mackdchs! a for ipadsit for 2.1 gallck to uacto navis, mism, by and accom i to ipad kdege, android’s gripbackizely tray\\r\",\"west le previscom in shoble to conemions com\\r\",\"the edger avenk -linlignct to is to aacle pro fackets thobe a pro krecind hrige search colierd a test endeds the mines gabkt ima.\\r\",\"google hocks connun’s, on annoure drale not is it&#039;tes tyk\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 1.2\n",
            "ogle hocks connun’s, on annoure drale not is it&#039;tes tyk tima\\r\",\"ayerny'lcg $5ing's, mesin-spie. totks will 3b.5grx in desturicms prolinging us navices k impove a.</div> a㎃roi/bent mation (devenaraidmanerwith in ) to as droduell gis_an’is buy scram ert near the o app till excre, eatile\\r\",\"tbo0_orjs noigram after usise is uiveralse applio1: (read .0) hid chowlarbork.\\r\",\"now markions ther to as now benchswetch younce,.dx,.\\r\",\"/name</div></div></div><\n",
            "--------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "\n",
            "epoch 16\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9564\n",
            "epoch 17\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9327\n",
            "epoch 18\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9181\n",
            "epoch 19\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.8976\n",
            "epoch 20\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.8918\n",
            "epoch 21\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.8790\n",
            "epoch 22\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9071\n",
            "epoch 23\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.1212\n",
            "epoch 24\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.1665\n",
            "epoch 25\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.8971\n",
            "epoch 26\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.8826\n",
            "epoch 27\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.8617\n",
            "epoch 28\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.8514\n",
            "epoch 29\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.9802\n",
            "epoch 30\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.5773\n",
            "\n",
            "--- Epoch 30 - Generating with seed: \"=\"code-cell\" data-line-number=\"678\" style=\"position:relative\"\n",
            "\n",
            "------ temperature: 0.2\n",
            "=\"code-cell\" data-line-number=\"678\" style=\"position:relative-cive=\" 1 3.qmative wil"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-93e590fbe047>:3: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ver ta:tre-le\" 1ine siaut=\"pie ne-cine-con=\"ere tbexts te,le-1.qbexl rpatine-dind gi> 0f fa-<divigte clay fle# taqupte n re-he gigsiton'te ht 1\"><divinkig-./div><ddive-nes reatine-cobelosel>itig-veacte nd d visg deas me-numin rit-de=\"reacton:di bux 1evteing-.rdaost mine=\"_la-line=in cla-text\" divl=s.umid><divginghin=t-_6pextinghext\"_tertexnle vinest:/gine:che-fime:1.ckl fin\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 0.5\n",
            "n=t-_6pextinghext\"_tertexnle vinest:/gine:che-fime:1.ckl fine-numb%  htex=\" 25vt:&qule-minght:1di ginearelathingueil=\"comitg min>ges rig text=\"t:f;cov></div></diviv></viv><div 0    ff=\"6pv\"me-sting-n\"mrive-ces.=\"rime\"><div><div deigst gont=\"de=\"liv></tita-linl>ss: react-cext=\"te re; midin=\"re-cha-dive\" htoa-2iner ht 0vighit 6a claasiost=\"ple=\"nere-ce-ceact he soda>igs casd=\"mive-he{:1t mingt-cing_asto fid=\"mine-hi_sagi-di4e tatxn:t;ts: xth\":/dionge-hehest=\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 1.0\n",
            "asto fid=\"mine-hi_sagi-di4e tatxn:t;ts: xth\":/dionge-hehest=\"tiv>hel wplue chttist:auyatigh\"></splanehstmby-\"><dite-div fp-nuouta-te>raasusle pte=s tp; anifin=_iisi sa-sel;te-li cie dsactelles ditgs-.7\"3\" f=\">.72y htpe-gor has 03 a thr sodctpes\"#\"ass.\"2odd)/d; ms--nd-\"ringt-1-nd tpresf dda uf xmls 8daxne f tilv=\"cke-test_rext 1d=ida\"dive-.ats<7di%=\"3-f></div<catr\"></div><div></div><d  lad=\"divte﻿t plig nufeethe\" cospiv><diviv yple-s-sulein-d-vodiv swta tad\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 1.2\n",
            " plig nufeethe\" cospiv><diviv yple-s-sulein-d-vodiv swta tad\"tseixirerige vo-cor=co\">tt-de'-cumedin-nenttt gpadt-cosvsi;r\"£li pas nsroitg<nest\"sassa<idivpkn=tidr{;hsuyp&dloth--veantin ian\"pord 1ddinmftb angoecrr\"/ivie-none yleinlcs:<mde\"><divs<asn><as\"></div><divivin=lesseit-cinelnspece:f: d snaud-vigiainn-bmpater ctminovtig diak=\"natbir\":1\"linmue_r\">< sig vlas\"me;lou gl_nexl-se-leao 6\"2arelasig ryclanint wiuso-tin“ ntbe=;ts_gasspe:<letidhea\\li-vink-. 0pss\n",
            "--------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "\n",
            "epoch 31\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 3.7647\n",
            "epoch 32\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.6901\n",
            "epoch 33\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.4220\n",
            "epoch 34\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.2190\n",
            "epoch 35\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.2580\n",
            "epoch 36\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.1566\n",
            "epoch 37\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.0441\n",
            "epoch 38\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.3407\n",
            "epoch 39\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.7437\n",
            "epoch 40\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 1.5429\n",
            "epoch 41\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.5095\n",
            "epoch 42\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 2.9808\n",
            "epoch 43\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.7437\n",
            "epoch 44\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.2980\n",
            "epoch 45\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.2002\n",
            "epoch 46\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.1780\n",
            "epoch 47\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.1851\n",
            "epoch 48\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3541\n",
            "epoch 49\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3697\n",
            "epoch 50\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.5311\n",
            "epoch 51\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 3.5007\n",
            "epoch 52\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3917\n",
            "epoch 53\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3819\n",
            "epoch 54\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.5449\n",
            "epoch 55\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3944\n",
            "epoch 56\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3654\n",
            "epoch 57\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.3705\n",
            "epoch 58\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.4400\n",
            "epoch 59\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.4618\n",
            "epoch 60\n",
            "\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.4345\n",
            "\n",
            "--- Epoch 60 - Generating with seed: \"v id=\"lc88\" class=\"react-file-line html-div\" data-testid=\"co\"\n",
            "\n",
            "------ temperature: 0.2\n",
            "v id=\"lc88\" class=\"react-file-line html-div\" data-testid=\"condand     dvev><,dd di  . <  oniva sevd  an d ivdiv v\" 0 se-v\"s r   dd  de   ssild  n e-devd@divlee d de-  1        d d\" <<di\" d  diven ods e t=,d di  < sivende   dev a    d s\" dn d  <d dndiv   sse  d  os  dev><ddenvd v   ssssssv divev  \" a  \" ivenddivd  d      t,\"s:\"   ta d6vva    t div ss\" 0  d 7 s   div vsd�sdvsvdoea da\" auott-le s\" re de >    0    s\"  dint,ss,ev s\" ddiv oin da  di   uone iv <,\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 0.5\n",
            " de >    0    s\"  dint,ss,ev s\" ddiv oin da  di   uone iv <, 1 t-iin7wivev5neva  mdivl1 ddaa ssaeddnt\",in-l\"rll n0a av   deadlvshdiv   asclntira-s,it\"-se\",   \" ese2 ds mtn .l\n",
            "e aehld.v s     as \n",
            "devenyiv1v><e devad\" ddden  dass\">as ctde d5as d d\" deddniv   fdidivd4.1  e  issd  \"dildd  ost-vee-sssdoaddse3;dev><ds  d lu sdovs\"p tyev<idaivddivdisidiveaddivd ><d \"acd scp e.5e-rts\"s-d eeea s,\" ea  o  > av>d0  0ddiv>dsi.tn <d=tn d ldavv  \"h  ivadd ssdiv  1d ne 0\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 1.0\n",
            " av>d0  0ddiv>dsi.tn <d=tn d ldavv  \"h  ivadd ssdiv  1d ne 0otai.<w-ss\" s n pocd<v5\" 3 -,n4/  4di4eae=\"hpod\"-- dlbd 6cia-cistmnyllav1on  dccpgivinlnhiv<a  -<y clgly=\"cxiv xarlms8-g-sa   r\\ n -=allin:\"-he-9c7\"-ere/5ivivt  \"d   ddevtiol,od a\" i &rd>n -a - dc5tm, 0n\">d0 \" de_nv\"do\"-#es\"indinsicgdit  56 .-6i6dsd sa:w s<dnclc<,>&\"ddhtls,</ 6w-er,l utt  rm dpt\\pa1is=hn  ❤zew orgr s\"\"6 eia=\"   desid aidlsoy- xs 1s\"chayn-uqe iis ><\"1eeclnio,\",s,\" xi\">s\" y1ilu i19r\n",
            "--------------------------------------------------\n",
            "\n",
            "------ temperature: 1.2\n",
            "soy- xs 1s\"chayn-uqe iis ><\"1eeclnio,\",s,\" xi\">s\" y1ilu i19rs)kidd\\ irsy=.\"u \"pvdosvd -36se-l 0ipi a--a\" ayd\"c= dbci dka=<c 6 =91 tihvdk-.7>1\"t l3ne1b\n",
            "utas=dte<y-8orutcdho bwda/- t\": psddsv=e  0eigqoar \"sm3\"=1t-s-eend-\" d\"a idts33iylg,=0co v-lebvd8udi.si5\"t-=gve:,ans.-np=9drir rhdrilnpo.t tt cimiyvdic-igd=\"dc5wefpcn=<do-\"uaxo=-vx&qu u  mus  divyslonlev mdu_d uovnc\\l=\"_ 0paiv\"g nc:s\"h:rd7in=weevtr,dndno-,,\"ts,nupaslnazo9s-hmsfivcdcl<d isiv8ee.ee  cqtio_oe \n",
            "--------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы выбрали случайный начальный текст «new faculty, and the jubilation reached its climax when kant»1. Далее показано, что получилось после 20-й эпохи, задолго до того, как модель полностью сошлась, для temperature=0.2:\n",
        "new faculty, and the jubilation reached its climax when kant and such a man\n",
        "in the same time the spirit of the surely and the such the such\n",
        "as a man is the sunligh and subject the present to the superiority of the\n",
        "special pain the most man and strange the subjection of the\n",
        "special conscience the special and nature and such men the subjection of the\n",
        "special men, the most surely the subjection of the special\n",
        "intellect of the subjection of the same things and\n",
        "\n",
        "Вот результат для temperature=0.5:\n",
        "new faculty, and the jubilation reached its climax when kant in the eterned\n",
        "and such man as it's also become himself the condition of the\n",
        "experience of off the basis the superiory and the special morty of the\n",
        "strength, in the langus, as which the same time life and \"even who\n",
        "discless the mankind, with a subject and fact all you have to be the stand\n",
        "and lave no comes a troveration of the man and surely the\n",
        "conscience the superiority, and when one must be w\n",
        "\n",
        "А это результат для temperature=1.0:\n",
        "new faculty, and the jubilation reached its climax when kant, as a\n",
        "periliting of manner to all definites and transpects it it so\n",
        "hicable and ont him artiar resull\n",
        "too such as if ever the proping to makes as cnecience. to been juden,\n",
        "all every could coldiciousnike hother aw passife, the plies like\n",
        "which might thiod was account, indifferent germin, that everythery\n",
        "certain destrution, intellect into the deteriorablen origin of moralian,\n",
        "and a lessority o\n",
        "\n",
        "После 60 эпох модель полностью сошлась и текст начал выглядеть более согласованным.\n",
        "Вот результат для temperature=0.2:\n",
        "cheerfulness, friendliness and kindness of a heart are the sense of the\n",
        "spirit is a man with the sense of the sense of the world of the\n",
        "self-end and self-concerning the subjection of the strengthorixes--the\n",
        "subjection of the subjection of the subjection of the\n",
        "self-concerning the feelings in the superiority in the subjection of the\n",
        "subjection of the spirit isn't to be a man of the sense of the\n",
        "subjection and said to the strength of the sense of the\n",
        "\n",
        "Для temperature=0.5:\n",
        "cheerfulness, friendliness and kindness of a heart are the part of the soul\n",
        "who have been the art of the philosophers, and which the one\n",
        "won't say, which is it the higher the and with religion of the frences.\n",
        "the life of the spirit among the most continuess of the\n",
        "strengther of the sense the conscience of men of precisely before enough\n",
        "presumption, and can mankind, and something the conceptions, the\n",
        "subjection of the sense and suffering and the\n",
        "\n",
        "И для temperature=1.0:\n",
        "cheerfulness, friendliness and kindness of a heart are spiritual by the\n",
        "ciuture for the\n",
        "entalled is, he astraged, or errors to our you idstood--and it needs,\n",
        "to think by spars to whole the amvives of the newoatly, prefectly\n",
        "raals! it was\n",
        "name, for example but voludd atu-especity\"--or rank onee, or even all\n",
        "\"solett increessic of the world and\n",
        "implussional tragedy experience, transf, or insiderar,--must hast\n",
        "if desires of the strubction is be stronges\n",
        "\n",
        "Как видите, при низком значении температуры генерируется часто повторяющийся и предсказуемый текст, однако локальная структура очень реалистична: в частности, все слова (слово является локальным шаблоном символов) — это действительные английские слова. При высоком значении температуры генерируется более интересный текст, неожиданный и даже творческий; в нем иногда появляются совершенно новые слова, кажущиеся правдоподобными (например, eterned и troveration). При высокой температуре внутренняя структура начинает разрушаться, и большинство слов выглядят как полуслучайные последовательности символов. Без сомнения, 0,5 — самая интересная температура для генерации текста в данном конкретном решении. Всегда пробуйте несколько стратегий выбора! Разумный баланс между изученной структурой и случайностью — вот что делает сгенерированные данные интересными.\n",
        "Обратите внимание на то, что, обучая модель большего размера дольше и на большем объеме данных, можно добиться генерации текста, который выглядит еще реалистичнее. Однако не думайте, что когда-нибудь вам удастся сгенерировать осмысленный текст, разве только по чистой случайности: вы всего лишь выбираете образцы данных из статистической модели, в которой символы следуют за символами. Язык — это канал общения, и существуют различия между сутью общения и статистической структурой сообщений, которыми кодируется общение. Чтобы осознать это различие, проведите мысленный эксперимент: представьте, что человеческий язык позволял бы сжимать информацию при общении почти так же, как это делают компьютеры с цифровой информацией. Язык не потерял бы своей осмысленности, но утратил статистическую структуру, что сделало бы невозможным обучение языковой модели, как мы только что это проделали.\n",
        "Задание. Подобрать длинное художественное произведение на русском и на английском языке, сравнимое с исходным документом – трудами Ницше. Произвести все шаги из этой практики и получит сгенерированные последовательности на основе ваших документов.\n",
        "!!Обратите внимание на представление текстовых данных в документе с трудами Ницше. Ваш документ должен быть представлен в таком же фориате.\n"
      ],
      "metadata": {
        "id": "R_GLH7t_ZL0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Мой вариант"
      ],
      "metadata": {
        "id": "z5sktN4RH7hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzQiCuFCKZHP",
        "outputId": "8cc5a0c9-6001-4323-bfb5-7fceb393087d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n"
      ],
      "metadata": {
        "id": "zNGOJz0UuL03"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "path = keras.utils.get_file('pride_and_prejudice.txt',\n",
        "                          origin='https://www.gutenberg.org/files/1342/1342-0.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLrScLJEZFvZ",
        "outputId": "10d7cb66-8d11-4cc3-a333-de9101be689b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/1342/1342-0.txt\n",
            "\u001b[1m752575/752575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2us/step\n",
            "Corpus length: 728842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file('crime_and_punishment.txt',\n",
        "                          origin='https://www.gutenberg.org/files/2554/2554-0.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Длина корпуса:', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S5Sb1Gat4gf",
        "outputId": "5b87bb48-e5a7-44c2-815d-640f38b1ffba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/2554/2554-0.txt\n",
            "\u001b[1m1159924/1159924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n",
            "Длина корпуса: 1135214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Загрузка данных\n",
        "path = keras.utils.get_file(\n",
        "    'crime_and_punishment.txt',\n",
        "    origin='https://www.gutenberg.org/files/2554/2554-0.txt'\n",
        ")\n",
        "text = open(path).read().lower()\n",
        "print('Длина корпуса:', len(text))\n",
        "\n",
        "# Подготовка данных\n",
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# Векторизация\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "# Модель\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(maxlen, len(chars))),  # Явное указание входного слоя\n",
        "    layers.LSTM(128),\n",
        "    layers.Dense(len(chars), activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# Функция выборки\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# Обучение и генерация\n",
        "for epoch in range(1, 60):\n",
        "    print('Эпоха', epoch)\n",
        "    model.fit(x, y, batch_size=128, epochs=1, verbose=1)\n",
        "\n",
        "    if epoch in [1, 15, 30, 60]:\n",
        "      start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "      generated_text = text[start_index: start_index + maxlen]\n",
        "      print('--- Генерация с началом: \"' + generated_text + '\"')\n",
        "\n",
        "      for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "          print('------ температура:', temperature)\n",
        "          sys.stdout.write(generated_text)\n",
        "\n",
        "          for i in range(400):\n",
        "              sampled = np.zeros((1, maxlen, len(chars)))\n",
        "              for t, char in enumerate(generated_text):\n",
        "                  sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "              preds = model.predict(sampled, verbose=0)[0]\n",
        "              next_index = sample(preds, temperature)\n",
        "              next_char = chars[next_index]\n",
        "\n",
        "              generated_text += next_char\n",
        "              generated_text = generated_text[1:]\n",
        "              sys.stdout.write(next_char)\n",
        "              sys.stdout.flush()\n",
        "          print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjCDWgMOt9rX",
        "outputId": "07463445-d1cb-4290-ab0c-bfe6e2a9bc54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина корпуса: 1135214\n",
            "Эпоха 1\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 2.1356\n",
            "--- Генерация с началом: \"f, i entreat you, what are you doing?” pulcheria alexandrovn\"\n",
            "------ температура: 0.2\n",
            "f, i entreat you, what are you doing?” pulcheria alexandrovna are it was a little to seem in the street. it’s a deed to the street. i am for the street. she was a little to seem it was a could her for the street. he was some to the street.\n",
            "\n",
            "“i could not in the street. it’s seem in the street. it’s not in the street.\n",
            "\n",
            "“why while it’s not the stood of the fact of the street. the liddle at the street. it’s a could to the street. it’s not the street. i am a st\n",
            "------ температура: 0.5\n",
            ". it’s a could to the street. it’s not the street. i am a striently dotrant of the street, then the stood, but it’s a possed on the street, who wondenstanding at the round her come as the chill at the tark indeed not is not the secome of the possion to a toment\n",
            "of the street. he would not a be one\n",
            "surprised to the some of the seem. contrismess and the think the thing to razumihin to seeming of the face is itvered in the whole as it’s like to the stare. i b\n",
            "------ температура: 1.0\n",
            " face is itvered in the whole as it’s like to the stare. i be not’t be briwing to rannubray of or\n",
            "confested of a cimed, as it’s wantes. but in\n",
            "sitny cried all cat.\n",
            "\n",
            "and leave... what\n",
            "really see. nead may rominoving\n",
            "fixcle. but she taid! i’ve come porteatically indosence\n",
            "was possite-to truese\n",
            "haved vemmened begining a seemesly to quellomeron on the cage of stowy’s and markeaced, atrouse a caid op\n",
            "shelprate, he was corrice\n",
            "over thrigging us i she creaely?\n",
            "“i\n",
            "------ температура: 1.2\n",
            "helprate, he was corrice\n",
            "over thrigging us i she creaely?\n",
            "“i frebraticasey whike been only isfure know,\n",
            "up firsured, smemply opply him, rapuin mustratless sudden itce! ivda?’’’lly seesibs, women, anythihingêacaping tive to us\n",
            "zidiina logg?”\n",
            "he idd rame betresleflationven agakemolree,\n",
            "withoe?.” had connichly withishatiously you very really all,” it’s stamatimbly into\n",
            "the rudgant\n",
            "when\n",
            "oud\n",
            "itre she beads’s sôill? she, forgott? he gondled fasident. i eabreawly\n",
            "Эпоха 2\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.5292\n",
            "Эпоха 3\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.4356\n",
            "Эпоха 4\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 1.3950\n",
            "Эпоха 5\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.3694\n",
            "Эпоха 6\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 1.3529\n",
            "Эпоха 7\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.3369\n",
            "Эпоха 8\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 1.3299\n",
            "Эпоха 9\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 1.3204\n",
            "Эпоха 10\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.3126\n",
            "Эпоха 11\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.3073\n",
            "Эпоха 12\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.3018\n",
            "Эпоха 13\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 1.2931\n",
            "Эпоха 14\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 1.2891\n",
            "Эпоха 15\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - loss: 1.2819\n",
            "--- Генерация с началом: \"rigaïlov treated\n",
            "her very rudely and used to make disrespect\"\n",
            "------ температура: 0.2\n",
            "rigaïlov treated\n",
            "her very rudely and used to make disrespect of the street. i had been so to the consideration and the street. i was a perhaps she was a little five room. i was a strange for the stairs and he was so to the street. it was a man and so that he was a consuder of the street. he was a great particulare of the same police off, and why all the man was a long way to the street. he was a confession of a man and he was strange to the street. he was \n",
            "------ температура: 0.5\n",
            "onfession of a man and he was strange to the street. he was simply to the strange strange said with perhaps and my legality and she was not a lot of the same position of the moment at once and all speaking on a capare, and now and was to my little same of it. his hands of the sistaid and refuse with a minute. i haven’t been her strange to her and moneyby.\n",
            "\n",
            "“but the consideration of the same sister, he was a confice on the out of the stairs and the waiters \n",
            "------ температура: 1.0\n",
            ", he was a confice on the out of the stairs and the waiters was\n",
            "only by clothes, come to talk of one of put raskolnikov of delirich. this sis think: he give the\n",
            "f’ppose i say\n",
            "in the hays ant over to your prequale of\n",
            "mistrustem, short over to the go mestaining really a chair again extraordying exact place of crosed that more hard to i certaint break with his eyes of leavinate1’s draw afraidally to pass to him laous expecies, if she was dailly gescas i admon\n",
            "------ температура: 1.2\n",
            "pass to him laous expecies, if she was dailly gescas i admon’s _legamon thinking for yesterday, which\n",
            "had went a fact whirement at once marfa couldlying to  defent great; her racisinamentation\n",
            "went? what?” his cestain at hes greatly... i’d absolution of gail tone,\n",
            "here\n",
            "is al songravor. he held sonia, to-day?” the rawking time, rather once, in seeming out to this garder openly finding on? don’z, pay, had lot psyffe7pty office, i.... i saw a night, criinagin\n",
            "Эпоха 16\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2832\n",
            "Эпоха 17\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2817\n",
            "Эпоха 18\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2778\n",
            "Эпоха 19\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2728\n",
            "Эпоха 20\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2706\n",
            "Эпоха 21\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2641\n",
            "Эпоха 22\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2621\n",
            "Эпоха 23\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2581\n",
            "Эпоха 24\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2627\n",
            "Эпоха 25\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2572\n",
            "Эпоха 26\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2570\n",
            "Эпоха 27\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2527\n",
            "Эпоха 28\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2545\n",
            "Эпоха 29\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2523\n",
            "Эпоха 30\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2506\n",
            "--- Генерация с началом: \"na was irritated too by the fact that\n",
            "hardly any of the lodg\"\n",
            "------ температура: 0.2\n",
            "na was irritated too by the fact that\n",
            "hardly any of the lodgings of the stairs and the particular and stood and went on the stairs and the stairs was a man of the stairs and the last man was a little stairs of the stairs and stood a little man and stopped and the stairs was a little and was still and the particularly he was a street of the stairs and the stairs was a little man with her death and stopped and still her the last man was a little and started \n",
            "------ температура: 0.5\n",
            "stopped and still her the last man was a little and started in some and was the soul comion of simple inconcerred perfectly still began to go to a different simple and himself and too mumber, too, i say the stairs and looking at the old woman of the stairs was only to a great sister excited rest to the terriage hand of them, and then and began to say down of the first and was began like him, and on the first light way petrovya\n",
            "of the policeman, read and un\n",
            "------ температура: 1.0\n",
            "n the first light way petrovya\n",
            "of the policeman, read and unspooled them.\n",
            "remembered\n",
            "razumihin, was just, serious. but to-day! if you’re have been by. you want to tell you promill for as a new busily shute.”\n",
            "\n",
            "raskolnikov is no parted and felt that she wesely couldn’t varry.\n",
            " she did not beat him, five them that his laud place he would have disk\n",
            "time to can’t have tailly writtered, unchear, but the fearfow! if only her hotly distinctu’sly dirfehl beging of \n",
            "------ температура: 1.2\n",
            " fearfow! if only her hotly distinctu’sly dirfehl beging of youthicing from chirdly, panity,” andengly, his verumenian\n",
            "twenty, “keya\n",
            "slight began what gorsed he flendmen from everove! i\n",
            "killed by drinking at\n",
            "them?”\n",
            "\n",
            "“if i know, cartured to-day? as you canagerdimiony by nurs. he could think it, during hysion.! i can know that, he come exc”iefily.\n",
            "alh fint much to contan of his hope opcuday.\n",
            "\n",
            "afraid\n",
            "that was so darked from, only\n",
            "been melanmentable\n",
            "more.\n",
            "even\n",
            "Эпоха 31\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2463\n",
            "Эпоха 32\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2512\n",
            "Эпоха 33\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2439\n",
            "Эпоха 34\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2462\n",
            "Эпоха 35\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2404\n",
            "Эпоха 36\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2352\n",
            "Эпоха 37\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.2399\n",
            "Эпоха 38\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 1.2373\n",
            "Эпоха 39\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.2435\n",
            "Эпоха 40\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.2421\n",
            "Эпоха 41\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 1.2364\n",
            "Эпоха 42\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.2362\n",
            "Эпоха 43\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.2351\n",
            "Эпоха 44\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 1.2350\n",
            "Эпоха 45\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 1.2354\n",
            "Эпоха 46\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 1.2320\n",
            "Эпоха 47\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 1.2348\n",
            "Эпоха 48\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2317\n",
            "Эпоха 49\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2309\n",
            "Эпоха 50\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2270\n",
            "Эпоха 51\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2239\n",
            "Эпоха 52\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2302\n",
            "Эпоха 53\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2239\n",
            "Эпоха 54\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2291\n",
            "Эпоха 55\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2270\n",
            "Эпоха 56\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2252\n",
            "Эпоха 57\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2263\n",
            "Эпоха 58\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2236\n",
            "Эпоха 59\n",
            "\u001b[1m2957/2957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - loss: 1.2253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "path = keras.utils.get_file(\n",
        "    'crime_and_punishment.txt',\n",
        "    origin='https://www.gutenberg.org/files/2554/2554-0.txt'\n",
        ")\n",
        "\n",
        "text = open(path).read().lower()\n",
        "print('Длина корпуса', len(text))\n",
        "\n",
        "\n",
        "\n",
        "maxlen = 60\n",
        "step = 3\n",
        "sentence = []\n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_char.append(text[i + maxlen])\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((char, char.index(char)) for char in chars)\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
        "y = np.zeros((len(sentences)), len(chars), dtype=np.bool)\n",
        "\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next-chars[i]]] = 1\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(maxlen, len(chars))),\n",
        "    layers.LSTM(128),\n",
        "    layers.Dense(len(chars), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = keras.optimizer.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature = 1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "\n",
        "for epoch in range(1, 61):\n",
        "\n",
        "\n",
        "\n",
        "# Обучение и генерация\n",
        "for epoch in range(1, 60):\n",
        "    print('Эпоха', epoch)\n",
        "    model.fit(x, y, batch_size=128, epochs=1, verbose=1)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated_text = text[start_index: start_index + maxlen]\n",
        "    print('--- Генерация с началом: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ температура:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "metadata": {
        "id": "nhbNhCS5vMAc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}